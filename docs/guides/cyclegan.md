[CycleGAN](https://github.com/junyanz/CycleGAN) is a powerful model that is capable of learning
image-to-image translation without input-output pairs.

In this guide, we will train a Torch model for replacing a horse in any image with a zebra.


## Setup project

For this guide we will be using a fork of [CycleGAN](https://github.com/houqp/CycleGAN) adapted for floydhub.

```bash
$ git clone https://github.com/houqp/CycleGAN
$ cd CycleGAN
$ floyd init cyclegan
```


## Training

### Dataset

The original CycleGAN already provides couple interesting datasets for
training. You can assess those datasets through floydhub data id
[f9RVzpea4vb9uCLaDggUgX](https://www.floydhub.com/viewer/data/f9RVzpea4vb9uCLaDggUgX/C96ydwuPgbHRdfu8hbH3L4/).
You can mount this at runtime using the `--data` parameter. For more information
on how data inputs work, see [Using Datasets](../home/using_datasets.md) and
the sample training command in the next section.


### Training

Training a horse to zebra transformer model can be done in one simple [command](../commands/run):

```bash
$ floyd run --gpu --env torch --data f9RVzpea4vb9uCLaDggUgX 'niter=3 niter_decay=3 bash ./floydhub/dream.sh horse2zebra'
```

Notes:

- The input dataset is passed using the `--data` parameter. This mounts the
pre-uploaded datasets at `/input` path. `dream.sh` is setup to automatically
lookup datasets from `/input`.
- The data id [f9RVzpea4vb9uCLaDggUgX](https://www.floydhub.com/viewer/data/f9RVzpea4vb9uCLaDggUgX/C96ydwuPgbHRdfu8hbH3L4/)
points to the pre-uploaded public dataset on FloydHub.
- The last argument for dream.sh tells it name of the dataset to use for
training, in this example we are using
[horse2zebra](https://www.floydhub.com/viewer/data/f9RVzpea4vb9uCLaDggUgX/C96ydwuPgbHRdfu8hbH3L4/datasets/horse2zebra/).
- The job is run on a GPU instance (because of the `--gpu` flag).
- This project uses Torch environment. (See the `--env` flag)
- For testing purpose, we pass in extra flags to restrict the iteration to
only 6 rounds (`niter + iter_decay`) to reduce the training time. To get a good
result, the project is setup to do 200 iterations by default, which will take
roughly 23 hours to finish on FloydHub GPU instance.

While the job is running, you can follow along the progress by using the
[logs](../commands/logs.md) command. Before the training starts, `dream.sh` will also install some
extra needed dependencies that are not included in FloydHub's Torch environment.

```bash
$ floyd logs <RUN_ID> -t
```

Floyd saves any content stored in the `/output` directory after the job is
finished. This output can be used as a data source in the next project using
`--data` flag. To get the ID of the output generated by your job use the
[info](../commands/info.md) command.

```bash
$ floyd info <RUN_ID>
```

The final trained model are named `latest_net_G_A.t7` and `latest_net_G_B.t7`.
The `net_G_A` model is trained to generate images like group B (zebra) using
images from group A (horse). You can also visually inspect the training result
for each epoch by viewing all the generated png files, which includes sampled
result from both directions.


### Testing

To test a CycleGAN model you trained on FloydHub, you will need to first get
the output ID for the training experiment using `floyd info` command.

Then you can use the following command to spin up the test:

```bash
floyd run --gpu --env torch --data TRAINING_OUTPUT_ID 'bash ./floydhub/test.sh horse2zebra ./test_images'
```

Notes:

- `./test_images` is a flat directory that contains images data you want to
test with. The directory name is arbitrary.

Once the test run is done, you should be able to view the result by opening the
`index.html` file in your experiment output with a browser.


## Rest API

Coming Soon!
